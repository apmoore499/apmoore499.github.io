<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><title>Spartan HPC Usage - Archer</title><link rel="shortcut icon" href="http://localhost:4000/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs.css"> <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Spartan HPC Usage | Archer</title><meta name="generator" content="Jekyll v3.8.5" /><meta property="og:title" content="Spartan HPC Usage" /><meta property="og:locale" content="en_US" /><meta name="description" content="PhD repository" /><meta property="og:description" content="PhD repository" /><link rel="canonical" href="http://localhost:4000/docs/hpc/spartan/" /><meta property="og:url" content="http://localhost:4000/docs/hpc/spartan/" /><meta property="og:site_name" content="Archer" /> <script type="application/ld+json"> {"@type":"WebPage","url":"http://localhost:4000/docs/hpc/spartan/","headline":"Spartan HPC Usage","description":"PhD repository","@context":"https://schema.org"}</script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="link" viewBox="0 0 16 16"><title>Link</title><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path> </symbol> </svg><div class="page-wrap"><div class="side-bar"><div class="site-header"> <a href="http://localhost:4000" class="site-title lh-tight"> Archer </a> <button class="menu-button fs-3 js-main-nav-trigger" data-text-toggle="Hide" type="button">Menu</button></div><div class="navigation main-nav js-main-nav"><nav role="navigation" aria-label="Main navigation"><ul class="navigation-list"><li class="navigation-list-item active"><a href="http://localhost:4000/docs/circuitSNP/code/6_split_data_for_denny_NN/" class="navigation-list-link"></a><li class="navigation-list-item active"><a href="http://localhost:4000/docs/circuitSNP/code/snp_vec_creation/" class="navigation-list-link"></a><li class="navigation-list-item"><a href="http://localhost:4000/docs/circuitSNP/code/split_data/" class="navigation-list-link">Now we split data</a><li class="navigation-list-item"><a href="http://localhost:4000/docs/github%20misc/github/" class="navigation-list-link">Github doc</a><li class="navigation-list-item active"><a href="http://localhost:4000/docs/hpc/copying_data_to_hpc/" class="navigation-list-link"></a><li class="navigation-list-item"><a href="http://localhost:4000/" class="navigation-list-link">Home</a><li class="navigation-list-item"><a href="http://localhost:4000/docs/circuitSNP/circuitSNP/" class="navigation-list-link">circuitSNP</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="http://localhost:4000/docs/circuitSNP/code/code_documentation/" class="navigation-list-link">Python Implementation</a><ul class="navigation-list-child-list"><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/1_preliminary_setup/" class="navigation-list-link">1. Environment Configuration</a><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/2_download_data/" class="navigation-list-link">2. Download data</a><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/3_analyse_lcl_chromatin/" class="navigation-list-link">3. Detect open / closed regions</a><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/4_analyse_motif_window_membership/" class="navigation-list-link">4. Motif membership</a><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/5_generate_T_matrix/" class="navigation-list-link">5. Generate T matrix</a><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/7_run_NN/" class="navigation-list-link">6. Run NN</a><li class="navigation-list-item "> <a href="http://localhost:4000/docs/circuitSNP/code/functions/" class="navigation-list-link">Imports and functions</a></ul></ul><li class="navigation-list-item active"><a href="http://localhost:4000/docs/hpc/spartan/" class="navigation-list-link active">Spartan HPC Usage</a><ul class="navigation-list-child-list "><li class="navigation-list-item "><a href="http://localhost:4000/docs/hpc/slurm/" class="navigation-list-link">Slurm example script</a></ul><li class="navigation-list-item"><a href="http://localhost:4000/docs/jekyll_maintenance/jekyll_setup/" class="navigation-list-link">Web Development</a></ul></nav></div><footer class="site-footer"><p class="text-small text-grey-dk-000 mb-4">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p></footer></div><div class="main-content-wrap js-main-content" tabindex="0"><div class="main-content"><div class="page-header js-page-header"><div class="search"><div class="search-input-wrap"> <input type="text" class="js-search-input search-input" tabindex="0" placeholder="Search Archer" aria-label="Search Archer" autocomplete="off"> <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg></div><div class="js-search-results search-results-wrap"></div></div></div><div class="page"><div id="main-content" class="page-content" role="main"><h2 id="some-notes-on-spartan--hpc-usage"> <a href="#some-notes-on-spartan--hpc-usage" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Some notes on Spartan / HPC usage</h2><h3 id="logging-in"> <a href="#logging-in" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Logging in</h3><p>Use <code class="language-plaintext highlighter-rouge">ssh &lt;username&gt;@spartan.hpc.unimelb.edu.au</code> to login via ssh terminal in linux/mac or else use PUTTY on windows machine</p><h3 id="starting-session-or-running-whatever"> <a href="#starting-session-or-running-whatever" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Starting session or running whatever</h3><p>When using spartan make sure to run code from a session - the default terminal interface runs on the login node and this is a common landing area for new users.</p><p><code class="language-plaintext highlighter-rouge">sinteractive</code> session very useful for debugging. Once verified to run on this node, can batch to run on hpc cluster via slurm</p><p>Start up the unit with following, for eg 20 mins. Change acct as necessary.</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sinteractive <span class="nt">--nodes</span> 1 <span class="nt">--account</span><span class="o">=</span>punim0614 <span class="nt">--partition</span> gpgpu <span class="nt">--qos</span><span class="o">=</span>gpgpumdhs <span class="nt">--gres</span><span class="o">=</span>gpu:p100:1 <span class="nt">--time</span> 01:00:00 <span class="nt">--cpus-per-task</span><span class="o">=</span>1
</code></pre></div></div><p>For 1hr</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sinteractive <span class="nt">--nodes</span> 1 <span class="nt">--account</span><span class="o">=</span>punim0614 <span class="nt">--partition</span> gpgpu <span class="nt">--qos</span><span class="o">=</span>gpgpumdhs <span class="nt">--gres</span><span class="o">=</span>gpu:p100:1 <span class="nt">--time</span> 01:00:00 <span class="nt">--cpus-per-task</span><span class="o">=</span>1
</code></pre></div></div><p>To specify more memory (40000MB in this case). If you don’t have enough memory sometimes you will get ‘process killed’ error.</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sinteractive <span class="nt">--nodes</span> 1 <span class="nt">--account</span><span class="o">=</span>punim0614 <span class="nt">--partition</span> gpgpu <span class="nt">--qos</span><span class="o">=</span>gpgpumdhs <span class="nt">--mem</span> 40000 <span class="nt">--gres</span><span class="o">=</span>gpu:p100:1 <span class="nt">--time</span> 01:00:00 <span class="nt">--cpus-per-task</span><span class="o">=</span>1
</code></pre></div></div><h1 id="loading-python-modules"> <a href="#loading-python-modules" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Loading python modules</h1><p>This is order of operation to set up environment for example relating to analysis for circuitSNP. The last command called in bash will overwrite any applicable libraries imported by other commands. For example, if importing python3.6.4 kernel, will backdate pandas to earlier version than that used in python3.6.10 kernel, but libraries not common to both will be left unaltered. This is particularly relevant for protobuf library which differs between various tensorflow versions, and the verison of pandas - as .pickle objects (serialised using pickle library in python) will not be compatible if the version of pandas used to save object is different from the verison used to load.</p><ol><li>load python module (you would only load one python module)<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#for python with CUDA9</span>
module load Python/3.6.4-intel-2017.u2-GCC-6.2.0-CUDA9
<span class="c">#for python with CUDA10</span>
module load Python/3.6.10-intel-2017.u2-GCC-6.2.0-CUDA10.1
</code></pre></div></div><li>then load tensorflow<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#for cuda9</span>
module load Tensorflow/2.1.0-intel-2017.u2-GCC-6.2.0-CUDA9-Python-3.6.4
<span class="c">#for cuda10</span>
module load Tensorflow/2.1.0-intel-2017.u2-GCC-6.2.0-CUDA10.1-Python-3.6.10-GPU
</code></pre></div></div><li>then load virutalenv<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>circuitSNP
<span class="nb">source</span> ./p6/bin/activate  <span class="c">#in circuitSNP directory...</span>
</code></pre></div></div></ol><p>All togeth for cuda9</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>module load Python/3.6.4-intel-2017.u2-GCC-6.2.0-CUDA9
module load Tensorflow/2.1.0-intel-2017.u2-GCC-6.2.0-CUDA9-Python-3.6.4
<span class="nb">cd </span>circuitSNP
<span class="nb">source</span> ./p6/bin/activate  <span class="c">#in circuitSNP directory...</span>
</code></pre></div></div><p>And for cuda10</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>module load Python/3.6.10-intel-2017.u2-GCC-6.2.0-CUDA10.1
module load Tensorflow/2.1.0-intel-2017.u2-GCC-6.2.0-CUDA10.1-Python-3.6.10-GPU
<span class="nb">source</span> ~/circuitSNP/p6c10/bin/activate  <span class="c">#in circuitSNP directory...</span>
</code></pre></div></div><h1 id="virtual-environment"> <a href="#virtual-environment" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Virtual environment</h1><p>To create new virtual env do following (note change python version if need). Calling venv will attempt to load that python module.</p><p>It’s important to call <code class="language-plaintext highlighter-rouge">module load web_proxy</code> so that the server can surf the web and download more modules</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>module load Python/3.6.4-intel-2017.u2-GCC-6.2.0-CUDA9
module load web_proxy
virtualenv &lt;venv name&gt;F
</code></pre></div></div><p>To install libraries for each cuda version:</p><h5 id="cuda9"> <a href="#cuda9" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Cuda9</h5><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>module load Python/3.6.4-intel-2017.u2-GCC-6.2.0-CUDA9
module load web_proxy
virtualenv
<span class="nb">source </span>venv/bin/activate
module load web_proxy
pip <span class="nb">install </span><span class="nv">pandas</span><span class="o">==</span>0.22.0
pip <span class="nb">install </span><span class="nv">protobuf</span><span class="o">==</span>3.8.0
</code></pre></div></div><h5 id="cuda10"> <a href="#cuda10" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> Cuda10</h5><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>module load Python/3.6.10-intel-2017.u2-GCC-6.2.0-CUDA10.1
module load web_proxy
virtualenv p6c10
<span class="nb">source </span>p6c10/bin/activate
pip <span class="nb">install </span>absl-py
pip <span class="nb">install </span><span class="nv">scipy</span><span class="o">==</span>1.4.1
pip <span class="nb">install </span><span class="nv">pandas</span><span class="o">==</span>0.22.0
pip <span class="nb">install </span>matplotlib
</code></pre></div></div><p>To double check compatibility of various python modules, call following:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip freeze
</code></pre></div></div><h5 id="gpu-usage-w-tensorflow"> <a href="#gpu-usage-w-tensorflow" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#link"></use></svg></a> GPU usage w tensorflow</h5><p>If using cuda10, we need to define model on the gpu device, otherwise tflow might run on CPU.</p><p>Force GPU usage using flag <code class="language-plaintext highlighter-rouge">with tf.device('/device:GPU:0'):</code> then that instance of <code class="language-plaintext highlighter-rouge">tf</code> refers to the GPU version of tflow kernel</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">tensorflow.python.client</span> <span class="kn">import</span> <span class="n">device_lib</span>
<span class="k">print</span><span class="p">(</span><span class="n">device_lib</span><span class="o">.</span><span class="n">list_local_devices</span><span class="p">())</span>

<span class="c1">#returns device as '/device:GPU:0'
</span>
<span class="n">NUMBER_OF_EPOCHS</span><span class="o">=</span><span class="mi">500</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'/device:GPU:0'</span><span class="p">):</span>
  <span class="n">Xtrain_v</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Xtrain_v</span><span class="p">)</span>
  <span class="n">Ytrain_v</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Ytrain_v</span><span class="p">)</span>
  <span class="n">Xval_v</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Xval_v</span><span class="p">)</span>
  <span class="n">Yval_v</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Yval_v</span><span class="p">)</span>
  <span class="n">Xtest_v</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Xtest_v</span><span class="p">)</span>
  <span class="n">Ytest_v</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Ytest_v</span><span class="p">)</span> 
  <span class="n">model1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span> <span class="c1">#model defined on GPU
</span>  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1372</span><span class="p">)))</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>
  <span class="n">model1</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adagrad'</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
  <span class="n">history1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">Xtrain_v</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">Ytrain_v</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">NUMBER_OF_EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">Xval_v</span><span class="p">,</span><span class="n">Yval_v</span><span class="p">))</span>
  <span class="n">model1</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'./models/model_batch_norm_every_5_3_128_.h5'</span><span class="p">)</span>
</code></pre></div></div><p>#####Misc / copying files</p><p>Copying files have following commands:</p><div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scp &lt;from_dir&gt; &lt;to_dir&gt;
</code></pre></div></div><p>Example on relevant data:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scp /home/doctorjonescore/Desktop/cdata/3_test_data.pickle apmoore@spartan.hpc.unimelb.edu.au:./circuitSNP/data/3_test_data.pickle
scp /home/doctorjonescore/Desktop/cdata/3_train_data.pickle apmoore@spartan.hpc.unimelb.edu.au:./circuitSNP/data/3_train_data.pickle
scp /home/doctorjonescore/Desktop/cdata/3_validation_data.pickle apmoore@spartan.hpc.unimelb.edu.au:./circuitSNP/data/3_validation_data.pickle
</code></pre></div></div><p>#####Slurm</p><p>Batch files using slurm, here example</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------
#!/bin/bash
#SBATCH --nodes 1
#SBATCH --account=punim0614
#SBATCH --qos=gpgpumdhs
#SBATCH --partition gpgpu
#SBATCH --gres=gpu:p100:1
#SBATCH --time 00:05:00
#SBATCH --cpus-per-task=1

module load Tensorflow/1.8.0-intel-2017.u2-GCC-6.2.0-CUDA9-Python-3.5.2-GPU
python tensor_flow.py
-------------
</code></pre></div></div><hr><h2 class="text-delta">Table of contents</h2><ul><li> <a href="http://localhost:4000/docs/hpc/slurm/">Slurm example script</a></ul></div></div></div></div>
